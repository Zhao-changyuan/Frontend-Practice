### 6.1 分页

#### 6.1.1 使用skip和limit实现分页

skip+limit只适合处理体量小的数据，数据一多就会卡顿，再怎么加索引、做优化，都没有办法解决。

#### 6.1.2 使用find和limit实现分页

_id是MongoDB中的ObjectID类型数据，ObjectID类型的数据占用12字节的存储空间，每个字节为两位十六进制数字，因此是一个24位的字符串，包括timestamp、machinid、processid、counter的内容。

使用_id实现分页的大致思路如下：

- 在当前页内查出最后一条记录的_id，记为last_id。
- 将记下来的last_id作为查询条件，如果查出大于last_id的记录，就将这些记录作为下一页的内容。

#### 6.1.3 ObjectID的组成

_id是ObjectID类型数据，有12字节组成，具有唯一性。按照字节顺序，ObjectID的前4字节表示时间戳（time），接下来的3字节是机器标识码（machine），紧跟着的2个字节为进程标识（pid），最后3个字节是自增计数器（inc）。

学习有3个境界，跟人学最快，跟书学次之，自悟最慢。最好的学习方式还是掌握阅读开源源码的方法，只要开源世界还在，你就可以随时随地进行学习。

#### 6.1.4 客户端生成ObjectID

MongoDB不仅可以通过自身的服务来生成ObjectID，还可以通过客户端的驱动程序来生成ObjectID。MongoDB的设计体现“用空间换时间”的思想。

### 6.2 关联查询

在关系型数据库里，表关联时最常用的操作。

#### 6.2.1 聚合函数

聚合函数是对一组数值执行计算并返回结果的函数，它经常与SELECT语句与GROUP BY子句一同使用。

在MongoDB里，aggregate函数可以实现类似查询的功能。

#### 6.2.2 聚合管道

MongoDB的聚合管道是一种数据处理方式，在一个管道处理完文档后将结果传递给下一个管道处理。管道操作是可以多次执行的，适用于复杂查询。

MongoDB的聚合操作会接受一个名为pipeline的参数和一个可选参数。pipeline可以理解为流水线，一条流水线上可以有一道或多道工序。

聚合操作是针对一个MongoDB表进行的操作，为了提高性能，最好的策略是将筛选“工序”放到最前面，尽早排除不满足条件的记录，降低后面工序的工作量。

#### 6.2.3 MapReduce

MapReduce是一个非常灵活和强大的数据聚合工具。它的好处是可以把一个聚合任务分配到多个服务器上并行处理。

一般而言，业务数据和统计数据是分离的。一般后台开发人员可能用不到MapReduce。

#### 6.2.4 关联关系

Mongoose封装了populate方法，在定义一个Schema时可以指定其中的字段（属性）是另一个Schema的引用，这样查询文档时就可以使用populate方法通过引用Schema和id找到关联的另一个文档或文档中的指定字段。

#### 6.2.5 aggregation

调用模型实例的aggregate方法将会返回aggregation实例，aggregation实例中又有一下方法和属性。

##### 1. append方法

##### 2. exec方法

##### 3. allowDiskUse方法

##### 4. cursor方法

##### 5. group方法

##### 6. limit方法

##### 7. match方法

match方法表示汇总计算的筛选条件。

##### 8. near方法

##### 9. read方法

##### 10. skip方法

##### 11. sort方法

##### 12. unwind方法

unwind方法用于将输入的文档数组解构。

##### 13. 操作符

- $and
- $or
- $not
- $setEquals 判断不同列中的对应值是否相同，如果相同就返回true。

### 6.3 事务

数据库中的事务（transaction）是指单个逻辑工作单位执行的一系列操作，这些操作要么全部执行，要么全部不执行。事务必须要满足4个属性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。

#### 6.3.1 二阶段提交法

从本质上来说，二阶段提交法的原理是，利用单个集合具备事务和状态机的特性，适当地增加字段作为元数据来描述必要信息，以便执行回滚操作。

##### 6.3.2 回滚操作

#### 6.4 性能调优

##### 6.4.1 profile

profile有4种设置项：

- 0：不开启profile。
- 1：记录慢查询，默认将耗时大与100ms的查询定义为慢查询。
- 2：记录所有查询结果。
- 3：查询采样记录。

#### 6.4.2 explain

MongoDB提供了db.collection.explain()、cursor.explain()两种explain，都会返回查询执行的统计信息。

#### 6.4.3 索引优化

MongoDB的索引几乎与关系型数据库的索引一模一样。

##### 在MongoDB中创建索引

创建索引要使用db.collectionName.ensureIndex()方法。

我们可以使用唯一索引来应对偶尔可能出现的键重复的问题。

在某些情况下，我们可能希望唯一索引仅对包含相应键的文档起作用。如果有一个字段可能存在也肯能不存在，那么该字段存在时就是唯一索引，不存在时则无需理会，这是就可以将unique和sparse选项组合在一起使用。

使用sparse选项可以创建稀疏索引。

##### Mongoose中的索引类型

4种索引：复合索引（2d）、地理空间索引（2dsphere）、哈希索引（hashed）、文本索引（text）。

**1. _id索引（default _id index）**

**2. 单字段索引（single field index）**

**3. 多键复合索引（multikey compound index）**

**4. 复合索引（compound index）**

**5. 地理空间索引（geospatial index）**

**6. 哈希索引**

**7. 文本索引**

#### 6.4.4 MongoDB的连接问题

##### 服务器假死

1. 查看sockstat状态
2. 使用ulimit设置能打开的文件的最大数目

##### 查看连接数

一般来说，默认的连接数是足够用的。如果有额外需要，可以在MongoDB启动的CLI里添加参数--maxConns=20000或者修改/etc/mongod.conf配置。注意修改了最大连接数后，一定要重启MongoDB进程。

##### 连接池

优化数据库连接最简单的办法就是使用数据库连接池。

注意，不要打开超过2000个连接。

在应用程序退出之后，关闭连接，同时注意某些地方的异常处理。

性能调优经验：通过设置native_parser来提升性能、合理配置连接池、操作数据库是养成好的习惯、清理会话（session）、及时关闭连接等。

用完即关。

#### 6.4.5 MongooseDao

DAO就是对单一模型操作的封装。

MongooseDao提供了更多的API，他们都是针对模型的操作方法，比如增删改查、分页等，这些API让数据库操作变得更加简便。

MongooseDao是对Mongoose操作的约定，提供了更方便的API封装，结合bluebird的promisifyAll可以更好地满足我们日常的业务需求。

#### 6.4.6 异步流程控制

##### 1. 内置Promise：mpromise对象

##### 2. 查询不是真正的Promise

如果要返回功能完整的Promise，可以使用.exec()方法。

##### 3. 使用Promise库

此时可以设置Mongoose.Promise

##### 4. MongoDB驱动的Promise

Mongoose.Promise用于配置Mongoose使用Promise属性，但是它不会影响底层MongoDB驱动的Promise。

##### 5. 使用bluebird的promisifyAll方法

可以把某个对象上的所有方法都变成返回Promise对象的方法。

promisifyAll是非常好的方法但不能滥用。如果贸然将普通方法转换为Promise，会产生性能问题。

##### 6. 使用co模块



总结一下，在数据库中可能用到的异步流程控制方法有很多，推荐采用如下方法。

- 使用bluebird模块，性能足够好，且不存在Node.js各个版本API不兼容问题。
- 模型操作使用promisifyAll包裹，这样可以批量将模型方法转成Promise，简化操作。
- 进行对外调用，无论是async函数，还是Promise都可以很好地和其他模块进行集成。

